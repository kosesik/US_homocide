---
title: "RML_project_US homocide"
author: "Krzysztof Osesik"
date: "30 04 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
Sys.setenv(LANGUAGE='en')
set.seed(123)
```

##

```{r, echo=FALSE}

# Setting up working directory
path_work<-"Z:/moje/moje/studia QPE/przedmioty/II semestr/Responsible ML/projekt/US homocide"
path_home<-"C:/Users/t420/Desktop/moje/studia QPE UW/przedmioty/II semestr/Responsible ML/projekt/US homocide"
path_home_2<-"C:/Users/Krzysztof_ASUS/Desktop/moje/studia QPE/przedmioty/II semestr/Responsible Machine Learning/project/US homocide"

location<-1

setwd(switch(location,path_work,path_home,path_home_2))

rm(list=ls())
```

# Introduction

## Problem Context

The Murder Accountability Project is the most complete database of homicides in the United States currently available. This dataset includes murders from the FBI's Supplementary Homicide Report from 1976 to the present and Freedom of Information Act data on more than 22,000 homicides that were not reported to the Justice Department. This dataset includes the age, race, sex, ethnicity of victims and perpetrators, in addition to the relationship between the victim and perpetrator and weapon used.

## Objectives

The goal of the analysis is to determine whether fairness of the model is maintained. To that end, we analyze whether identified protected variables affect the outcome of the crime investigation. In the data set victim's age, race and sex were identified as protected variables and whether a crime was solved or not was identified as target variable. In addition, explainability analysis was also conducted.

To sum up, the following are the objectives of the project:

1) Exploratory Data Analysis
2) Construction of predictive model
3) Explainability analysis
4) Assessment of model's fairness


## Data

The data set consists of nearly 640,000 crime cases. They are described by 24 variables, for example City, State, Year, Crime Type, Victim's Age, Perpetrator's Age and Weapon Used. 

Crime Solved was chosen as target variable. This variable defines whether a crime was solved or not. The remaining of 23 variables was chosen to be independent variables ( not all of which are relevant).

The data is however imbalanced, as we have less than 30% of cases where crime remained unsolved. This will need to be dealt with in the process of the analysis.


Loading required libraries.

```{r, results="hide",, message=FALSE, warning=FALSE}
library(MASS)
library(tidyverse)
library(corrplot)
library(tidyselect)
library(scales)
library(dgof)
library(caTools)
library(pROC)
library(dummy)
library(smotefamily)
library(officer)
library(ROSE)
library(pscl)
library(caret)
library(OptimalCutpoints)
library(randomForest)
library(arm)
library(e1071)
library(DescTools)
library(reshape2)
library(lime)
library(DALEX)
library(vip)
library(pdp)
library(fairness)
library(DALEXtra)
library(fastshap)
```

Loading the data.

```{r, results="hide",, message=FALSE, warning=FALSE}
# data<-read_csv(file = "database.csv")

# save(data,file="data.R")
load("data.R")
data_org<-data

```

Let's take an initial glance at the data.

```{r}
dim(data)
View(data)
summary(data)
str(data)
```

Column names have spaces. Let's replace them with "_".


```{r, echo=TRUE, results="hide"}
temp<-colnames(data)

temp<-gsub(" ","_",temp)

colnames(data)<-temp


```

The dataset is for all U.S. states for years 1980-2014. However, we are only interested in a subset of that, namely in results for five states of Louisina,Alabama, Mississipi, Georgia and South Carolina (so-called US Deep South States) in the 1980s decade (1980-1989). These five states were known to be have been rather unfriendly to minorities, especially black minorities in those and previous years. 

```{r}
data<-subset(data, data$State %in% c("Louisiana","Alabama","Mississipi", "Georgia","South Carolina") & between(data$Year,1980, 1989))


```


Let's check if there are any empty values.


```{r}

temp<-sum(sapply(data,function(x) (length(x)==length(data$'Record_ID'))))-ncol(data)

if( temp==0){
  
  cat("There are no empty cells in the dataset and every column is equal in length.")
  
} else{
  
  cat("There are",temp,"column(s) in the dataset with empty cells.")
}
```


Now, let's check if there are any missing values.


```{r}

temp<-sum(sapply(data,function(x) (is.na(x))))

if( temp==0){
  
  cat("There are no missing values in the dataset")
  
} else{
  
  cat("There are",temp,"missing value(s) in the dataset.")
}
```
Since there is only 1 missing values in the dataset we can remove it from the data.

```{r}

data<-data[complete.cases(data),]

```

Let's remove variables which will not be used in the analysis.

```{r}
temp<-c("Record_ID" ,"Agency_Code","Agency_Name", "City", "State", "Year","Month","Incident","Record_Source", "Victim_Ethnicity", "Perpetrator_Ethnicity",
     "Crime_Type","Agency_Name","Perpetrator_Count","Perpetrator_Race","Perpetrator_Age","Perpetrator_Sex", "Relationship" )

data<-data[,-(which(colnames(data) %in% temp))]


```

Let's focus on cases with perpetrators over 18 years old and remove cases with Victim_age equal to 998.

```{r}

data<-subset(data,Victim_Age>=18 & Victim_Age!=998)

```



Let's turn character variables into factor.


```{r}

data<-data %>% 
 mutate_if(is.character,as.factor) 

```

Let's attach the data.

```{r}
attach(data)
```


# Exploratory Data Analysis

Let's look at the histogram of only two numerical variables in the dataset.

```{r}

data %>% 
  select(Victim_Age, Crime_Solved) %>% 
  ggplot(aes(x=Victim_Age,fill=Crime_Solved))+geom_density(alpha=0.4)+theme_bw()

# data %>% 
#   select(Perpetrator_Age, Crime_Solved) %>% 
#   ggplot(aes(x=Perpetrator_Age,fill=Crime_Solved))+geom_density(alpha=0.4)+theme_bw()



```

For ease of analysis, let's now turn numerical variables into categorical ones.

Let's group categorical variables into fewer levels.

# FEATURE ENGINEERING

```{r}
# temp<-c("Crime_Solved", "Victim_Age")
# 
# temp<-colnames(data[,-which(colnames(data) %in% temp)])
# 
# df_levs<-data.frame()
#  
# for ( i in temp){
#   
#   levs<-data %>% 
#     select(as.name(i)) %>% 
#     unique()%>%
#     pull()%>%
#     as.character()
#     
#   
#   for ( j in levs){
#     
#   data_adj<-subset(data,eval(as.name(i))==j)
#       
#     
#   not_solved<-length(data_adj$Crime_Solved[data_adj$Crime_Solved=="No"])
#   solved<-length(data_adj$Crime_Solved[data_adj$Crime_Solved=="Yes"])
#   
#   df_levs<-rbind(df_levs,cbind(i, j,not_solved,solved))
#   
#   
#   }
#   
#   
#   
# }
# rm(data_adj)
# 
# df_levs$not_solved<-as.numeric(df_levs$not_solved)
# df_levs$solved<-as.numeric(df_levs$solved)
# 
# 
# df_levs<-df_levs%>%
#   dplyr::mutate(ratio=not_solved/(solved+not_solved))%>%
#   arrange(desc(ratio))
# 
# df_levs
# 
# 

data<-subset(data,subset=Victim_Sex!="Unknown" & Victim_Race!="Unknown")


data$Victim_Sex<-droplevels(data$Victim_Sex,exclude = anyNA(levels(data$Victim_Sex)))
data$Victim_Race<-droplevels(data$Victim_Race,exclude = anyNA(levels(data$Victim_Race)))


detach(data)

data$Weapon<-as.character(data$Weapon)
# levs<-levels(data$Relationship)
# data$Relationship<-as.character(data$Relationship)


temp<-c("Firearm","Gun","Handgun","Rifle","Shotgun")

data$Weapon[which(data$Weapon %in% temp)]<-"Gun"

temp<-c("Strangulation","Suffocation")

data$Weapon[which(data$Weapon %in% temp)]<-"Suffocation"

data$Weapon<-as.factor(data$Weapon)



# temp<-levs[c(1,14,19)]
# 
# data$Relationship[which(data$Relationship %in% temp)]<-"Acquaintance"
# 
# temp<-levs[c(4,20)]
# 
# data$Relationship[which(data$Relationship %in% temp)]<-"Siblings"
# 
# temp<-levs[c(8,9)]
# 
# data$Relationship[which(data$Relationship %in% temp)]<-"Workplace"
# 
# temp<-levs[c(22:25)]
# 
# data$Relationship[which(data$Relationship %in% temp)]<-"Step- relations"
# 
# temp<-levs[c(2,3,15)]
# 
# data$Relationship[which(data$Relationship %in% temp)]<-"Boyfriend/ Girlfriend"
# 
# temp<-levs[c(5,10,16)]
# 
# data$Relationship[which(data$Relationship %in% temp)]<-"Husband"
# 
# temp<-levs[c(6,11,28)]
# 
# data$Relationship[which(data$Relationship %in% temp)]<-"Wife"
# 
# # data$Relationship<-droplevels(data$Weapon,exclude = anyNA(levels(data$Relationship)))
# 
# data$Weapon<-as.factor(data$Weapon)
# data$Relationship<-as.factor(data$Relationship)
# rm(levs)

attach(data)


#
data$Victim_Age<-cut(data$Victim_Age,breaks=c(18,30,45,60,75,100), labels = c("18-30","30-45","45-60","60-75","75+"),right = FALSE)

# data$Perpetrator_Age<-cut(data$Perpetrator_Age,breaks=c(seq(15,65,10),100), labels = c("15-25","25-35","35-45","45-55","55-65","65+"),right=FALSE)
#
# data$Victim_Count<-as.factor(data$Victim_Count)
#
# data$Perpetrator_Count<-as.factor(data$Perpetrator_Count)


```


Let's look at some distributions of categorical variables.


```{r}

temp<-colnames(data)

# ppt<-read_pptx("RML_project.pptx")

# ppt %>% officer::layout_properties()

for (i in (temp)){
  
p<-data %>% 
  select(as.name(i)) %>% 
  ggplot(aes(x=eval(parse(text=i)),y=..count../sum(..count..)))+geom_bar(fill="sky blue",position = "dodge")+
  labs(y="Frequency", x=i)+
  theme_bw()+
  geom_text(aes(label=round(..count../sum(..count..),3)*100,y=(..count../sum(..count..))),stat="count",vjust=-.1)+
    theme(axis.text.x = element_text(angle=90))

print(p)

# 
# ppt<-ppt %>% 
#   add_slide(master="Content",layout="Wykres") %>% 
#   ph_with(value=p,location=ph_location_label(ph_label="Plot"))
   
  
}



```



Now, take a look at conditional distributions for protected categorical variables, i.e. Victim_Sex,  Victim_Race and Victim_Age. 

```{r}


  p<-data %>% 
  select(Crime_Solved,Victim_Sex) %>% 
  ggplot(aes(x=Victim_Sex, group=Crime_Solved, y=(..prop..), fill=factor(..x..)))+geom_bar(position ="dodge")+
    facet_grid(~Crime_Solved)+
    geom_text(aes(y=(..prop..),label=scales::percent(round(..prop..,3))),stat="count", vjust=-.5)+
    scale_y_continuous(labels=scales::percent, limits=c(0,0.9))+
    labs(y="Percent", fill=Victim_Sex)+
    scale_fill_discrete(labels = levels(Victim_Sex))+
    theme_bw()+
    theme(axis.text.x = element_text(angle = 90))


print(p)



# 
#   p<-data %>%
#   select(Crime_Solved,Perpetrator_Sex) %>%
#   ggplot(aes(x=Perpetrator_Sex, group=Crime_Solved, y=(..prop..), fill=factor(..x..)))+geom_bar(position ="dodge")+
#     facet_grid(~Crime_Solved)+
#     geom_text(aes(y=(..prop..),label=scales::percent(round(..prop..,3))),stat="count", vjust=-.5)+
#     scale_y_continuous(labels=scales::percent, limits=c(0,1))+
#     labs(y="Percent", fill=Perpetrator_Sex)+
#     scale_fill_discrete(labels = levels(Perpetrator_Sex))+
#     theme_bw()+
#     theme(axis.text.x = element_text(angle = 90))
# 
# 
# print(p)


  p<-data %>%
  select(Crime_Solved,Weapon) %>%
  ggplot(aes(x=Weapon, group=Crime_Solved, y=(..prop..), fill=factor(..x..)))+geom_bar(position ="dodge")+
    facet_grid(~Crime_Solved)+
    geom_text(aes(y=(..prop..),label=scales::percent(round(..prop..,3))),stat="count", vjust=-.5)+
    scale_y_continuous(labels=scales::percent, limits=c(0,1))+
    labs(y="Percent", fill=Weapon)+
    scale_fill_discrete(labels = levels(Weapon))+
    theme_bw()+
    theme(axis.text.x = element_text(angle = 90))


print(p)












#   p<-data %>% 
#   select(Crime_Solved,Relationship) %>% 
#   ggplot(aes(x=Relationship, group=Crime_Solved, y=(..prop..), fill=factor(..x..)))+geom_bar(position ="dodge")+
#     facet_grid(~Crime_Solved)+
#     geom_text(aes(y=(..prop..),label=scales::percent(round(..prop..,3))),stat="count", vjust=-.5)+
#     scale_y_continuous(labels=scales::percent, limits=c(0,1))+
#     labs(y="Percent", fill=Relationship)+
#     scale_fill_discrete(labels = levels(Relationship))+
#     theme_bw()+
#     theme(axis.text.x = element_text(angle = 90))
# 
# 
# print(p)
# 









# ppt<-ppt %>% 
#   add_slide(master="Content",layout="Wykres") %>% 
#   ph_with(value=p,location=ph_location_label(ph_label="Plot"))
   
  
  p<-data %>% 
  select(Crime_Solved,Victim_Race) %>% 
  ggplot(aes(x=Victim_Race, group=Crime_Solved, y=(..prop..), fill=factor(..x..)))+geom_bar(position ="dodge")+
    facet_grid(~Crime_Solved)+
    geom_text(aes(y=(..prop..),label=scales::percent(round(..prop..,3))),stat="count", vjust=-.5)+
    scale_y_continuous(labels=scales::percent, limits=c(0,0.6))+
    labs(y="Percent", fill=Victim_Race)+
    scale_fill_discrete(labels = levels(Victim_Race))+
    theme_bw()+
    theme(axis.text.x = element_text(angle = 90))
   
   print(p)
# 
# ppt<-ppt %>% 
#   add_slide(master="Content",layout="Wykres") %>% 
#   ph_with(value=p,location=ph_location_label(ph_label="Plot"))
   
   
  #  p<-data %>%
  # select(Crime_Solved,Victim_Age) %>%
  # ggplot(aes(x=Victim_Age, group=Crime_Solved, y=(..prop..), fill=factor(..x..)))+geom_bar(position ="dodge")+
  #   facet_grid(~Crime_Solved)+
  #   geom_text(aes(y=(..prop..),label=scales::percent(round(..prop..,3))),stat="count", vjust=-.5)+
  #   scale_y_continuous(labels=scales::percent, limits=c(0,1))+
  #   labs(y="Percent", fill=Victim_Age)+
  #   scale_fill_discrete(labels = levels(Victim_Age))+
  #   theme_bw()+
  #   theme(axis.text.x = element_text(angle = 90))
  # 
  #     print(p)

# ppt<-ppt %>% 
#   add_slide(master="Content",layout="Wykres") %>% 
#   ph_with(value=p,location=ph_location_label(ph_label="Plot"))
      
      
     # print(ppt,target="RML_project.pptx") 
 
```

Let's take a look at correlation (association) between categorical variables in the dataset. I will use Thiel's uncertainty coefficient to that end.

```{r}

cor_df<-matrix(0,nrow=ncol(data), ncol=ncol(data), dimnames=list(colnames(data),colnames(data)))

for (i in 1:ncol(data)){
  
  for (j in 1:ncol(data)){
    
    temp<-UncertCoef(table(data[[i]],data[[j]]), direction = "column")
    
    cor_df[i,j]<-temp
    
  }
  
}

cor_df<-round(cor_df, 2)
cor_df<-melt(cor_df)

ggplot(cor_df,aes(x=Var1,y=Var2,fill=value))+geom_tile()+labs(title = "Uncertainity Coefficient for categorical variables")+geom_text(aes(Var1, Var2, label = value), color = "black", size = 4)+scale_fill_gradient(low="white", high="blue") 


```

The variables are not correlated.



# MODELLING

Let's first divide the dataset into training and test sets.

```{r}
temp<-sample.split(data$Crime_Solved,SplitRatio = 0.7)

train_set<-subset(data, temp==TRUE)
test_set<-subset(data, temp==FALSE)

```

Let's see if proportions of Yes/No in target variable are maintained.

```{r}
round(prop.table(table(data$Crime_Solved)),4)*100
round(prop.table(table(train_set$Crime_Solved)),4)*100
round(prop.table(table(test_set$Crime_Solved)),4)*100

```

Proportions of binary responses of target variable have been maintained in the training and testing sets. Now, we need to deal with high imbalance of the training dataset. To that end, we will apply both oversampling and undersampling methods. This method was found to provide better results than oversampling and/or undersampling on a stand-alone basis.


```{r}

train_set_balanced<-ovun.sample(Crime_Solved~., data=train_set,method="both",p=0.5)
        #                        N=2*length(train_set$Crime_Solved[train_set$Crime_Solved=="No"]))
                                # p=0.5 

train_set_balanced<-train_set_balanced$data

table(train_set_balanced$Crime_Solved)


```


## LOGISTIC REGRESSION

Let's start predictive modelling. First, logistic regression model will be applied.

```{r}
train_set_balanced$Crime_Solved<-ifelse(train_set_balanced$Crime_Solved=="Yes",1,0)

train_set_balanced$Crime_Solved<-factor(train_set_balanced$Crime_Solved, levels=c(0,1))

model_log<-glm(Crime_Solved~.,data=train_set_balanced, family=binomial (link="logit"))

summary(model_log)

# model_log2<-bayesglm(Crime_Solved~.,data=train_set_balanced, family=binomial (link="logit"))

# summary(model_log2)



pR2(model_log)["McFadden"]

vars_imp<-varImp(model_log)

vars_type<-rownames(vars_imp)

vars_imp<-cbind(vars_type,vars_imp)

rownames(vars_imp)<-NULL

head(vars_imp[order(vars_imp$Overall,decreasing = TRUE),],10)


anova(model_log, test="Chisq")


test_set$Crime_Solved<-ifelse(test_set$Crime_Solved=="Yes",1,0)

pred_log<-predict(model_log, test_set[-2],type="response")
pred_log_bin<-ifelse(pred_log>=0.5,1,0)

confusionMatrix(as.factor(pred_log_bin),as.factor(test_set$Crime_Solved), positive = "0")

# ROCR curve

roc<-roc(test_set$Crime_Solved~pred_log,plot=TRUE,print.auc=TRUE,col="green",lwd =4,legacy.axes=TRUE,main="ROC Curve - Logistic Regression")





# opt_cp_df<-data.frame(pred=pred_log, observed=test_set$Crime_Solved)
# 
# opt_cp<-optimal.cutpoints(X="pred", status="observed",methods = "Youden", data=opt_cp_df, tag.healthy = "1")
# 
# summary(opt_cp)
# 
# plot(opt_cp)


```

Let's look at the results of logistic regression modelling with a use of cross-valdiation.

```{r}

ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
mod_log_cv <- train(Crime_Solved~.,  data=train_set_balanced, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5)

pred_log_cv <- predict(mod_log_cv, newdata=test_set[-2], type="prob")

pred_log_cv_bin<-ifelse(pred_log>=0.5,1,0)

confusionMatrix(as.factor(pred_log_cv_bin),as.factor(test_set$Crime_Solved))

# ROCR curve

roc<-roc(test_set$Crime_Solved~pred_log_cv[,2],plot=TRUE,print.auc=TRUE,col="green",lwd =4,legacy.axes=TRUE,main="ROC Curve - Logistic Regression Cross Validation")
```

The results with or without the use of cross-validation are identical. Now, let's apply random forest algorithm.


##Random Forest

```{r}

# model_rf<-randomForest(x=train_set_balanced[-2],
#                        y=train_set_balanced$Crime_Solved,
#                        ntree=100)

model_rf<-randomForest(Crime_Solved~.,data=train_set_balanced, ntree=30 )

# model_rf<-caret::train(Crime_Solved ~ ., data = train_set_balanced,method = "rf",
# trControl = trainControl(method = "repeatedcv", number = 10,repeats = 5, verboseIter = FALSE))


pred_rf<-predict(model_rf,newdata=test_set[-2],type="prob")

pred_rf_bin<-ifelse(pred_rf[,2]>0.5,1,0)

confusionMatrix(as.factor(pred_rf_bin),as.factor(test_set$Crime_Solved))

roc<-roc(test_set$Crime_Solved~pred_rf[,2],plot=TRUE,print.auc=TRUE,col="green",lwd =4,legacy.axes=TRUE,main="ROC Curve - Random Forest")


model_rf


obb_error_df<-data.frame(
  Trees=rep(1:nrow(model_rf$err.rate), times=3),
  Type=rep(c("OOB","0","1"), each=nrow(model_rf$err.rate)),
  Error=c(model_rf$err.rate[,"OOB"],
          model_rf$err.rate[,"0"],
          model_rf$err.rate[,"1"]))


ggplot(data=obb_error_df, aes(x=Trees, y=Error))+geom_line(aes(color=Type))+theme_bw()


varImp<-importance(model_rf)

varImpPlot(model_rf)

# plot(varImp(model_rf))


oob_values<-vector(length=10)

for (i in 1:(ncol(data)-1)){
  
  temp_model_rf<-randomForest(Crime_Solved~.,data=train_set_balanced, ntree=30,mtry=i)
  
  oob_values[i]<-temp_model_rf$err.rate[nrow(temp_model_rf$err.rate),1]
  
}

```



## SVM


```{r}

set.seed(123)



model_svm_tuned<-tune(svm,Crime_Solved~.,data=train_set_balanced,
                      kernel="radial",
                      ranges=list(gamma=2^(1),cost=10^(1)))

model_svm_tuned$best.parameters

```

Let's use the best parameters found by tuning the svm model.



```{r}


model_svm<-svm(Crime_Solved~.,data=train_set_balanced, kernel="radial",
               gamma=model_svm_tuned$best.parameters$gamma,
               cost=model_svm_tuned$best.parameters$cost,
               type="C-classification",
               scale=TRUE)

# model_svm_linera<-svm(Crime_Solved~.,
#                       data=train_set_balanced,
#                       kernel="sigmoid", gamma=0.1, cost=0.1, scale=FALSE)


summary(model_svm)


# op<-sapply(train_set_balanced[,-2],as.numeric)
# op[,1:5]<-op[,1:5]-1
# model_svm_tuned<-tune.svm(x=op,
#                           y=train_set_balanced[,2],
#                           gamma=5*10^(-2:2),
#                           cost=10^(-2:2),
#                           type="C-classification",
#                           kernel="radial", 
#                           scale=FALSE)



# model_svm_tuned



pred_svm<-predict(model_svm,newdata=test_set[-2])
# pred_svm_tuned<-predict(model_svm_tuned,newdata=test_set[-2])
# pred_svm_linear<-predict(model_svm_linera,newdata=test_set[-2])

confusionMatrix(as.factor(pred_svm),as.factor(test_set$Crime_Solved))
# confusionMatrix(as.factor(pred_svm_tuned),as.factor(test_set$Crime_Solved))
# confusionMatrix(as.factor(pred_svm_linear),as.factor(test_set$Crime_Solved))



# dummies <- dummyVars(~ ., data=train_set_balanced[,-2])
# c2 <- predict(dummies, train_set_balanced[,-2])
# d_training <- as.data.frame(cbind(train_set_balanced[,2], c2))
# 
# dummies <- dummyVars(~ ., data=test_set[,-2])
# c2 <- predict(dummies, test_set[,-2])
# d_test <- as.data.frame(cbind(test_set[,2], c2))
# 
# ### SVM ###
# 
# gammalist <- c(0.005,0.01,0.015,0.02,0.025,0.03,0.035,0.04,0.045,0.05)
# tune.out <- tune.svm(as.factor(V1) ~., data=d_training,
#                  kernel='radial', cost=2^(-1:5), gamma = gammalist)



```

# EXPLAINABILITY  ANALYSIS

For the purpose of explainabaility analysis I will focus on the Random Forest model, as it performs better than logistic regression model and svm model in terms of sensitivity, i.e. correctly identifying not solved cases from a subset of not solved cases (TP/ TP +FN). On the other hand, differences in overall accuracy are not considerable.

## VARIABLE IMPORTANCE PLOTS

```{r}

explain_rf <- DALEX::explain(model = model_rf,  
                        data = test_set[,-2],
                           y = test_set$Crime_Solved,
                        label="Random Forest")


# loss_root_mean_square(observed = test_set$Crime_Solved, 
#                    predicted = predict(model_rf, test_set))
                   

set.seed(123)
vip_50<-model_parts(explainer = explain_rf, 
        loss_function = loss_root_mean_square,
                    B = 30,
        type="raw")


plot(vip_50)










# vip(model_rf,geom="point", horizontal = FALSE, size = 1.5) 


```



## PARTIAL DEPENDENCE PLOTS


```{r}

explain_rf <- DALEX::explain(model = model_rf,  
                        data = test_set[,-2],
                           y = test_set$Crime_Solved,
                        label="Random Forest")


pdp_fun<-function(x){
  
  
  
  pdp_rf<-model_profile(explainer=explain_rf, variables=x,
                        # groups=,
                        )
  

}

col_n<-colnames(test_set)[-2]


for (i in seq_along(col_n)){
  
print(plot(pdp_fun(col_n[i])))
  
}






# pdp<-function(x){
#   
# temp<-pdp::partial(model_rf, pred.var = x, chull = TRUE, rug=TRUE, plot=TRUE)
# # autoplot(temp, contour = TRUE)
#   
#   
# }
# 
# col_n<-colnames(test_set)[-2]
# 
# for (i in seq_along(col_n)){
#   
# print(pdp(col_n[i]))
#   
# }



```



##LIME

```{r}

model_rf<-as_classifier(model_rf, labels = NULL)

test_set$Crime_Solved<-as.factor(test_set$Crime_Solved)
test_set$Victim_Count<-as.numeric(test_set$Victim_Count)


# test_set<-cbind(Id=(1:nrow(test_set)),test_set)

explainer <- lime(train_set_balanced[,-2], model_rf, quantile_bins = FALSE)

set.seed(123)

d_test<-subset(test_set,test_set$Victim_Race=="Black"& test_set$Victim_Age=="75+"&test_set$Weapon=="Gun"& test_set$Agency_Type=="Sheriff"&test_set$Victim_Sex=="Male")

explanation <- lime::explain(d_test[c(3:4,(nrow(d_test)-1):nrow(d_test)),-2], explainer,n_labels=1, n_features = 6, n_permutations=100)


explanation


plot_features(explanation)






# explain_rf <- DALEX::explain(model = model_rf,
#                         data = test_set[,-2],
#                            y = test_set$Crime_Solved,
#                         label="Random Forest")
# 
# lime <- predict_surrogate(explainer = explain_rf,
#                   new_observation = d_test[3:5,-2],
#                   n_features = 2,
#                   n_permutations = 1000,
#                   type = "lime"
#                   )
# 
# as.data.frame(lime)
# 
# plot(lime)



```

## SHAPLEY VALUES

Now, let's look at an alternative approach, i.e. so-called Shapley values.

```{r}

explain_rf <- DALEX::explain(model = model_rf,  
                        data = test_set[,-2],
                           y = test_set$Crime_Solved,
                        label="Random Forest")
predict(explain_rf, test_set[3:5,])



shap <- predict_parts(explainer = explain_rf, 
                      new_observation = d_test[3,], 
                                 type = "shap",
                                    B = 25)

shap

plot(shap)

```



# FAIRNESS ANALYSIS

## PREDICTIVE RATE PARITY


```{r}

test_set_fair<-cbind(test_set,pred_rf)

colnames(test_set_fair)[(ncol(test_set_fair)-1):ncol(test_set_fair)]<-c("probs_0","probs_1")

prp_sex <- pred_rate_parity(data         = test_set_fair, 
                         outcome      = "Crime_Solved", 
                         outcome_base = '1', 
                         group        = 'Victim_Sex',
                         probs        = 'probs_1', 
                         cutoff       = 0.5, 
                         base         = 'Female')

prp_sex


prp_race <- pred_rate_parity(data         = test_set_fair, 
                         outcome      = "Crime_Solved", 
                         outcome_base = '1', 
                         group        = 'Victim_Race',
                         probs        = 'probs_1', 
                         cutoff       = 0.5, 
                         base         = 'Black')

prp_race



prp_age <- pred_rate_parity(data         = test_set_fair, 
                         outcome      = "Crime_Solved", 
                         outcome_base = '1', 
                         group        = 'Victim_Age',
                         probs        = 'probs_1', 
                         cutoff       = 0.5, 
                         base         = '30-45')

prp_age



```

## DEMOGRAPHIC PARITY


```{r}


dem_par_sex <- dem_parity(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '1', 
                      group        = 'Victim_Sex',
                      probs        = 'probs_1',
                      base         = "Female")
dem_par_sex



dem_par_race <- dem_parity(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '1', 
                      group        = 'Victim_Race',
                      probs        = 'probs_1',
                      base         = "Black")
dem_par_race



dem_par_age <- dem_parity(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '1', 
                      group        = 'Victim_Age',
                      probs        = 'probs_1',
                      base         = "30-45")
dem_par_age


```


## PROPORTIONAL PARITY

```{r}

prop_par_sex <- prop_parity(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '1', 
                      group        = 'Victim_Sex',
                      probs        = 'probs_1',
                      base         = "Female")
prop_par_sex


prop_par_race <- prop_parity(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '1', 
                      group        = 'Victim_Race',
                      probs        = 'probs_1',
                      base         = "Black")
prop_par_race


prop_par_age <- prop_parity(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '1', 
                      group        = 'Victim_Age',
                      probs        = 'probs_1',
                      base         = "30-45")
prop_par_age




```



## EQUALIZED ODDS

```{r}

eq_odds_sex <- equal_odds(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '1', 
                      group        = 'Victim_Sex',
                      probs        = 'probs_1',
                      base         = "Female")
eq_odds_sex


eq_odds_race <- equal_odds(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '1', 
                      group        = 'Victim_Race',
                      probs        = 'probs_1',
                      base         = "Black")
eq_odds_race




eq_odds_age <- equal_odds(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '1', 
                      group        = 'Victim_Age',
                      probs        = 'probs_1',
                      base         = "30-45")
eq_odds_age


```




