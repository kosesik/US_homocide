---
title: "RML_project_US homocide"
author: "Krzysztof Osesik"
date: "15 06 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
Sys.setenv(LANGUAGE='en')
set.seed(123)
```

##

```{r, echo=FALSE}

# Setting up working directory
path_work<-"Z:/moje/moje/studia QPE/przedmioty/II semestr/Responsible ML/projekt/US homocide"
path_home<-"C:/Users/t420/Desktop/moje/studia QPE UW/przedmioty/II semestr/Responsible ML/projekt/US homocide"
path_home_2<-"C:/Users/Krzysztof_ASUS/Desktop/moje/studia QPE/przedmioty/II semestr/Responsible Machine Learning/project/US homocide"

location<-1

setwd(switch(location,path_work,path_home,path_home_2))

rm(list=ls())
```

# Introduction

## Problem Context

The Murder Accountability Project is the most complete database of homicides in the United States currently available. This dataset includes murders from the FBI's Supplementary Homicide Report from 1976 to the present. 

Dataset comes from Kaggle (https://www.kaggle.com/murderaccountability/homicide-reports).

The dataset consists of nearly 640,000 crime cases. They are described by 24 variables, for example City, State, Year, Crime Type, Victim's Age, Perpetrator's Age and Weapon Used. 


## Stakeholder

A stakeholder could be associated with a public authority aiming at ensuring that – in a case of a murder – identical effort is put into investigation with no regard for the victim’s race, sex or age. As a result similar crimes should be solved (alternatively not solved) independent of the victim’s race, sex  and age. 

The stakeholder is thus interested in evaluating the model’s general performance.  Their goal is to analyze whether there is some bias in police investigations towards certain social groups, which effectively results in a lower rate of solved crimes for those groups. 


## Objectives

The goal of the analysis is to determine whether fairness of the model is maintained. To that end, I analyze whether identified protected variables affect the outcome of the crime investigation. In the dataset victim's age, race and sex were identified as protected variables and whether a crime was solved or not was identified as target variable. In addition, explainability analysis was also conducted.

To sum up, the following are the objectives of the project:

1) Exploratory Data Analysis
2) Construction of predictive model
3) Explainability analysis
4) Assessment of model's fairness


## Data

The dataset consists of nearly 640,000 crime cases. They are described by 24 variables, for example City, State, Year, Crime Type, Victim's Age, Perpetrator's Age and Weapon Used. 

Crime Solved was chosen as target variable. This variable defines whether a crime was solved or not. The remaining of 23 variables was chosen to be independent variables ( not all of which are relevant).

In the final model, the following variables were used:

*Target variable*
* Crime Solved 

*Explanatory variables*
1.	Agency Type (e.g. County Police, State Police, etc.)
2.	Victim’s Sex (Female, Male)
3.	Victim’s Race (e.g. Black, White, Native, etc.)
4.	Victim’s Age ( continuous 18-100 years old)
5.	Weapon (e.g. Knife, Gun, Poison, etc.)
6.	Victim’s Count ( how many additional victims there were – integral 0 – 10 people)

*Protected variables*
1.	Victim’s Sex
2.	Victim’s Race
3.	Victim’s Age 

In addition, in order to increae computational efficiency, the dataset was reduced to look only at crimes in five U.S. States, i.e. Louisiana, Alabama, Mississippi, Georgia and South Carolina, which are known to be less friendly towards ethnic minorities (especially black). The timeframe of the analysis is 1980s (1980-1989).


The data is imbalanced, as there is less than 30% of cases where crime remained unsolved. This will need to be dealt with in the process of the analysis.


Loading required libraries.

```{r, results="hide",, message=FALSE, warning=FALSE}
library(MASS)
library(tidyverse)
library(corrplot)
library(tidyselect)
library(scales)
library(dgof)
library(caTools)
library(pROC)
library(dummy)
library(smotefamily)
library(officer)
library(ROSE)
library(pscl)
library(caret)
library(OptimalCutpoints)
library(randomForest)
library(arm)
library(e1071)
library(DescTools)
library(reshape2)
library(lime)
library(DALEX)
library(vip)
library(pdp)
library(fairness)
library(DALEXtra)
library(fastshap)
```

Loading the data.

```{r, results="hide",, message=FALSE, warning=FALSE}
# data<-read_csv(file = "database.csv")

# save(data,file="data.R")
load("data.R")
data_org<-data

```

Let's take an initial glance at the data.

```{r}
dim(data)
# View(data)
summary(data)
str(data)
```

Column names have spaces. Let's replace them with "_".


```{r, echo=TRUE, results="hide"}
temp<-colnames(data)

temp<-gsub(" ","_",temp)

colnames(data)<-temp


```

The dataset is for all U.S. states for years 1980-2014. However, we are only interested in a subset of that, namely in results for five states of Louisina,Alabama, Mississipi, Georgia and South Carolina (so-called US Deep South States) in the 1980s decade (1980-1989). These five states were known to be have been rather unfriendly to minorities, especially black minorities in those and previous years. 

```{r}
data<-subset(data, data$State %in% c("Louisiana","Alabama","Mississipi", "Georgia","South Carolina") & between(data$Year,1980, 1989))


```


Let's check if there are any empty values.


```{r}

temp<-sum(sapply(data,function(x) (length(x)==length(data$'Record_ID'))))-ncol(data)

if( temp==0){
  
  cat("There are no empty cells in the dataset and every column is equal in length.")
  
} else{
  
  cat("There are",temp,"column(s) in the dataset with empty cells.")
}
```


Now, let's check if there are any missing values.


```{r}

temp<-sum(sapply(data,function(x) (is.na(x))))

if( temp==0){
  
  cat("There are no missing values in the dataset")
  
} else{
  
  cat("There are",temp,"missing value(s) in the dataset.")
}
```
Since there is only 1 missing values in the dataset we can remove it from the data.

```{r}

data<-data[complete.cases(data),]

```

Let's remove variables which will not be used in the analysis.

```{r}
temp<-c("Record_ID" ,"Agency_Code","Agency_Name", "City", "State", "Year","Month","Incident","Record_Source", "Victim_Ethnicity", "Perpetrator_Ethnicity",
     "Crime_Type","Agency_Name","Perpetrator_Count","Perpetrator_Race","Perpetrator_Age","Perpetrator_Sex", "Relationship" )

data<-data[,-(which(colnames(data) %in% temp))]


```

Let's focus on cases with perpetrators over 18 years old and remove cases with Victim_age equal to 998.

```{r}

data<-subset(data,Victim_Age>=18 & Victim_Age!=998)

```



Let's turn character variables into factor.


```{r}

data<-data %>% 
 mutate_if(is.character,as.factor) 

```

Let's attach the data.

```{r}
attach(data)
```


# Exploratory Data Analysis

Let's look at the histogram of only two numerical variables in the dataset.

```{r}

data %>% 
  select(Victim_Age, Crime_Solved) %>% 
  ggplot(aes(x=Victim_Age,fill=Crime_Solved))+geom_density(alpha=0.4)+theme_bw()


```

For ease of analysis, let's now turn numerical variables into categorical ones.

Let's group categorical variables into fewer levels.

# FEATURE ENGINEERING

```{r}


data<-subset(data,subset=Victim_Sex!="Unknown" & Victim_Race!="Unknown")


data$Victim_Sex<-droplevels(data$Victim_Sex,exclude = anyNA(levels(data$Victim_Sex)))
data$Victim_Race<-droplevels(data$Victim_Race,exclude = anyNA(levels(data$Victim_Race)))


detach(data)

data$Weapon<-as.character(data$Weapon)

temp<-c("Firearm","Gun","Handgun","Rifle","Shotgun")

data$Weapon[which(data$Weapon %in% temp)]<-"Gun"

temp<-c("Strangulation","Suffocation")

data$Weapon[which(data$Weapon %in% temp)]<-"Suffocation"

data$Weapon<-as.factor(data$Weapon)


attach(data)

data$Victim_Age<-cut(data$Victim_Age,breaks=c(18,30,45,60,75,100), labels = c("18-30","30-45","45-60","60-75","75+"),right = FALSE)


```


Let's look at some distributions of categorical variables.


```{r}

temp<-colnames(data)

for (i in (temp)){
  
p<-data %>% 
  select(as.name(i)) %>% 
  ggplot(aes(x=eval(parse(text=i)),y=..count../sum(..count..)))+geom_bar(fill="sky blue",position = "dodge")+
  labs(y="Frequency", x=i)+
  theme_bw()+
  geom_text(aes(label=round(..count../sum(..count..),3)*100,y=(..count../sum(..count..))),stat="count",vjust=-.1)+
    theme(axis.text.x = element_text(angle=90))

print(p)


}



```



Now, take a look at conditional distributions for protected categorical variables, i.e. Victim_Sex,  Victim_Race and Victim_Age. 

```{r}


  p<-data %>% 
  select(Crime_Solved,Victim_Sex) %>% 
  ggplot(aes(x=Victim_Sex, group=Crime_Solved, y=(..prop..), fill=factor(..x..)))+geom_bar(position ="dodge")+
    facet_grid(~Crime_Solved)+
    geom_text(aes(y=(..prop..),label=scales::percent(round(..prop..,3))),stat="count", vjust=-.5)+
    scale_y_continuous(labels=scales::percent, limits=c(0,0.9))+
    labs(y="Percent", fill=Victim_Sex)+
    scale_fill_discrete(labels = levels(Victim_Sex))+
    theme_bw()+
    theme(axis.text.x = element_text(angle = 90))


print(p)


  p<-data %>%
  select(Crime_Solved,Weapon) %>%
  ggplot(aes(x=Weapon, group=Crime_Solved, y=(..prop..), fill=factor(..x..)))+geom_bar(position ="dodge")+
    facet_grid(~Crime_Solved)+
    geom_text(aes(y=(..prop..),label=scales::percent(round(..prop..,3))),stat="count", vjust=-.5)+
    scale_y_continuous(labels=scales::percent, limits=c(0,1))+
    labs(y="Percent", fill=Weapon)+
    scale_fill_discrete(labels = levels(Weapon))+
    theme_bw()+
    theme(axis.text.x = element_text(angle = 90))


print(p)


  p<-data %>% 
  select(Crime_Solved,Victim_Race) %>% 
  ggplot(aes(x=Victim_Race, group=Crime_Solved, y=(..prop..), fill=factor(..x..)))+geom_bar(position ="dodge")+
    facet_grid(~Crime_Solved)+
    geom_text(aes(y=(..prop..),label=scales::percent(round(..prop..,3))),stat="count", vjust=-.5)+
    scale_y_continuous(labels=scales::percent, limits=c(0,0.6))+
    labs(y="Percent", fill=Victim_Race)+
    scale_fill_discrete(labels = levels(Victim_Race))+
    theme_bw()+
    theme(axis.text.x = element_text(angle = 90))
   
   print(p)

```

Let's take a look at correlation (association) between categorical variables in the dataset. I will use Thiel's uncertainty coefficient to that end.

```{r}

cor_df<-matrix(0,nrow=ncol(data), ncol=ncol(data), dimnames=list(colnames(data),colnames(data)))

for (i in 1:ncol(data)){
  
  for (j in 1:ncol(data)){
    
    temp<-UncertCoef(table(data[[i]],data[[j]]), direction = "column")
    
    cor_df[i,j]<-temp
    
  }
  
}

cor_df<-round(cor_df, 2)
cor_df<-melt(cor_df)

ggplot(cor_df,aes(x=Var1,y=Var2,fill=value))+geom_tile()+labs(title = "Uncertainity Coefficient for categorical variables")+geom_text(aes(Var1, Var2, label = value), color = "black", size = 4)+scale_fill_gradient(low="white", high="blue") 


```

The variables are not correlated.



# MODELLING

Let's first divide the dataset into training and test sets.

```{r}
temp<-sample.split(data$Crime_Solved,SplitRatio = 0.7)

train_set<-subset(data, temp==TRUE)
test_set<-subset(data, temp==FALSE)

```

Let's see if proportions of Yes/No in target variable are maintained.

```{r}
round(prop.table(table(data$Crime_Solved)),4)*100
round(prop.table(table(train_set$Crime_Solved)),4)*100
round(prop.table(table(test_set$Crime_Solved)),4)*100

```

Proportions of binary responses of target variable have been maintained in the training and testing sets. Now, we need to deal with high imbalance of the training dataset. To that end, we will apply both oversampling and undersampling methods. This method was found to provide better results than oversampling and/or undersampling on a stand-alone basis.


```{r}

train_set_balanced<-ovun.sample(Crime_Solved~., data=train_set,method="both",p=0.5)

train_set_balanced<-train_set_balanced$data

table(train_set_balanced$Crime_Solved)


```


## LOGISTIC REGRESSION

Let's start predictive modelling. First, logistic regression model will be applied. Let's look at its summary.

```{r}
train_set_balanced$Crime_Solved<-ifelse(train_set_balanced$Crime_Solved=="Yes",1,0)

train_set_balanced$Crime_Solved<-factor(train_set_balanced$Crime_Solved, levels=c(0,1))

model_log<-glm(Crime_Solved~.,data=train_set_balanced, family=binomial (link="logit"))

summary(model_log)

```

Some dummy variables are indicated assignificant. Now, let's look at some other diagnostics.


```{r}

pR2(model_log)["McFadden"]

vars_imp<-varImp(model_log)

vars_type<-rownames(vars_imp)

vars_imp<-cbind(vars_type,vars_imp)

rownames(vars_imp)<-NULL

head(vars_imp[order(vars_imp$Overall,decreasing = TRUE),],10)


anova(model_log, test="Chisq")

```


From the anova analysis, it looks like for the logistic regression model - Weapon, Agency Type and Victim's Age are the most important explanatory variables. 

Now, let's try predict values based on a test set data and evaluate confusion matrix and ROC curve.

```{r}

test_set$Crime_Solved<-ifelse(test_set$Crime_Solved=="Yes",1,0)

pred_log<-predict(model_log, test_set[-2],type="response")
pred_log_bin<-ifelse(pred_log>=0.5,1,0)

confusionMatrix(as.factor(pred_log_bin),as.factor(test_set$Crime_Solved), positive = "0")


roc<-roc(test_set$Crime_Solved~pred_log,plot=TRUE,print.auc=TRUE,col="green",lwd =4,legacy.axes=TRUE,main="ROC Curve - Logistic Regression")


```

Let's look at the results of logistic regression modeling with a use of cross-valdiation.

```{r}

ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
mod_log_cv <- train(Crime_Solved~.,  data=train_set_balanced, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5)

pred_log_cv <- predict(mod_log_cv, newdata=test_set[-2], type="prob")

pred_log_cv_bin<-ifelse(pred_log>=0.5,1,0)

confusionMatrix(as.factor(pred_log_cv_bin),as.factor(test_set$Crime_Solved))


roc<-roc(test_set$Crime_Solved~pred_log_cv[,2],plot=TRUE,print.auc=TRUE,col="green",lwd =4,legacy.axes=TRUE,main="ROC Curve - Logistic Regression Cross Validation")

```

The results with or without the use of cross-validation are identical.


Now, let's apply random forest algorithm using randomForest package.


##Random Forest

```{r}

model_rf<-randomForest(Crime_Solved~.,data=train_set_balanced, ntree=30 )

pred_rf<-predict(model_rf,newdata=test_set[-2],type="prob")

pred_rf_bin<-ifelse(pred_rf[,2]>0.5,1,0)

confusionMatrix(as.factor(pred_rf_bin),as.factor(test_set$Crime_Solved))

roc<-roc(test_set$Crime_Solved~pred_rf[,2],plot=TRUE,print.auc=TRUE,col="green",lwd =4,legacy.axes=TRUE,main="ROC Curve - Random Forest")


model_rf

```

Let's look at some aditional diagnostics for the random forest model.


```{r}

obb_error_df<-data.frame(
  Trees=rep(1:nrow(model_rf$err.rate), times=3),
  Type=rep(c("OOB","0","1"), each=nrow(model_rf$err.rate)),
  Error=c(model_rf$err.rate[,"OOB"],
          model_rf$err.rate[,"0"],
          model_rf$err.rate[,"1"]))


ggplot(data=obb_error_df, aes(x=Trees, y=Error))+geom_line(aes(color=Type))+theme_bw()


varImp<-importance(model_rf)

varImpPlot(model_rf)


oob_values<-vector(length=10)

for (i in 1:(ncol(data)-1)){
  
  temp_model_rf<-randomForest(Crime_Solved~.,data=train_set_balanced, ntree=30,mtry=i)
  
  oob_values[i]<-temp_model_rf$err.rate[nrow(temp_model_rf$err.rate),1]
  
}

```


Now, let us apply support vector mechanism (SVM) algorithm.


## SVM


```{r}

set.seed(123)



model_svm_tuned<-tune(svm,Crime_Solved~.,data=train_set_balanced,
                      kernel="radial",
                      ranges=list(gamma=2^(1),cost=10^(1)))

model_svm_tuned$best.parameters

```

Let's use the best parameters found by tuning the svm model.



```{r}


model_svm<-svm(Crime_Solved~.,data=train_set_balanced, kernel="radial",
               gamma=model_svm_tuned$best.parameters$gamma,
               cost=model_svm_tuned$best.parameters$cost,
               type="C-classification",
               scale=TRUE)


summary(model_svm)

```

Let's predict repsonses based on test set and evaluate confusion matrix.

```{r}

pred_svm<-predict(model_svm,newdata=test_set[-2])


confusionMatrix(as.factor(pred_svm),as.factor(test_set$Crime_Solved))




```

SVM performs very similarly to Random forest model. However, Random forest model, at the cost of slightly worse model accuracy (positive prediction value is the same) fares better in terms of sensitivity metrics, i.e. in identifying positive cases ( for the purpose of our analysis "positive case" is associated with crime not-solved - factor level "0"). Therefore, in the subsequent parts, i.e. explainability analysis and fairness analysis Random forest will be used.



# EXPLAINABILITY  ANALYSIS

In the explainability part I will focus on:

1.two global metrics:

  +     variable importance plots
  +     partial dependence plots
  
2. two local metrics:

  +     LIME
  +     Shapley Values



## VARIABLE IMPORTANCE PLOTS

```{r}

explain_rf <- DALEX::explain(model = model_rf,  
                        data = test_set[,-2],
                           y = test_set$Crime_Solved,
                        label="Random Forest")


# loss_root_mean_square(observed = test_set$Crime_Solved, 
#                    predicted = predict(model_rf, test_set))
                   

set.seed(123)
vip_50<-model_parts(explainer = explain_rf, 
        loss_function = loss_root_mean_square,
                    B = 30,
        type="raw")


plot(vip_50)


```



## PARTIAL DEPENDENCE PLOTS


```{r}

explain_rf <- DALEX::explain(model = model_rf,  
                        data = test_set[,-2],
                           y = test_set$Crime_Solved,
                        label="Random Forest")


pdp_fun<-function(x){
  
  
  
  pdp_rf<-model_profile(explainer=explain_rf, variables=x,
                        # groups=,
                        )
  

}

col_n<-colnames(test_set)[-2]


for (i in seq_along(col_n)){
  
print(plot(pdp_fun(col_n[i])))
  
}



```



##LIME

```{r}

model_rf<-as_classifier(model_rf, labels = NULL)

test_set$Crime_Solved<-as.factor(test_set$Crime_Solved)
test_set$Victim_Count<-as.numeric(test_set$Victim_Count)


explainer <- lime(train_set_balanced[,-2], model_rf, quantile_bins = FALSE)

set.seed(123)

d_test<-subset(test_set,test_set$Victim_Race=="Black"& test_set$Victim_Age=="75+"&test_set$Weapon=="Gun"& test_set$Agency_Type=="Sheriff"&test_set$Victim_Sex=="Male")

explanation <- lime::explain(d_test[c(3:4,(nrow(d_test)-1):nrow(d_test)),-2], explainer,n_labels=1, n_features = 6, n_permutations=100)


explanation


plot_features(explanation)


```

## SHAPLEY VALUES

Now, let's look at an alternative approach, i.e. so-called Shapley values.

```{r}

explain_rf <- DALEX::explain(model = model_rf,  
                        data = test_set[,-2],
                           y = test_set$Crime_Solved,
                        label="Random Forest")
predict(explain_rf, test_set[3:5,])



shap <- predict_parts(explainer = explain_rf, 
                      new_observation = d_test[3,], 
                                 type = "shap",
                                    B = 25)

shap

plot(shap)

```


Now, let's turn to fairness analysis. Here I will use four metrics:

1. Predictive rate parity
2. Demographic parity
3. Proportional parity
4. Equalized odds

At the stage of explanatory model analysis, I identyfied three potential protected variables, i.e.:

1.	Victim’s Sex
2.	Victim’s Race
3.	Victim’s Age

However, in all models applied, and in the Random Forest in particular Victim's Race does not seem to be a significant variable, which indicates that racial profiling did not have much weight on crime investigations. In turn, out of the three protected variables, Victim's Age seems most significant, followed by Victim's Sex. Thus, in the subsequent fairness analysis I will only focus on these two protected variables.

# FAIRNESS ANALYSIS

## PREDICTIVE RATE PARITY


```{r}

test_set_fair<-cbind(test_set,pred_rf)

colnames(test_set_fair)[(ncol(test_set_fair)-1):ncol(test_set_fair)]<-c("probs_0","probs_1")

prp_sex <- pred_rate_parity(data         = test_set_fair, 
                         outcome      = "Crime_Solved", 
                         outcome_base = '1', 
                         group        = 'Victim_Sex',
                         probs        = 'probs_1', 
                         cutoff       = 0.5, 
                         base         = 'Female')

prp_sex



prp_age <- pred_rate_parity(data         = test_set_fair, 
                         outcome      = "Crime_Solved", 
                         outcome_base = '1', 
                         group        = 'Victim_Age',
                         probs        = 'probs_1', 
                         cutoff       = 0.5, 
                         base         = '30-45')

prp_age



```

## DEMOGRAPHIC PARITY


```{r}


dem_par_sex <- dem_parity(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '1', 
                      group        = 'Victim_Sex',
                      probs        = 'probs_1',
                      base         = "Female")
dem_par_sex



dem_par_age <- dem_parity(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '1', 
                      group        = 'Victim_Age',
                      probs        = 'probs_1',
                      base         = "30-45")
dem_par_age


```


## PROPORTIONAL PARITY

```{r}

prop_par_sex <- prop_parity(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '1', 
                      group        = 'Victim_Sex',
                      probs        = 'probs_1',
                      base         = "Female")
prop_par_sex


prop_par_age <- prop_parity(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '1', 
                      group        = 'Victim_Age',
                      probs        = 'probs_1',
                      base         = "30-45")
prop_par_age



```



## EQUALIZED ODDS

```{r}

eq_odds_sex <- equal_odds(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '1', 
                      group        = 'Victim_Sex',
                      probs        = 'probs_1',
                      base         = "Female")
eq_odds_sex



eq_odds_age <- equal_odds(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '1', 
                      group        = 'Victim_Age',
                      probs        = 'probs_1',
                      base         = "30-45")
eq_odds_age


```


# SUMMARY


