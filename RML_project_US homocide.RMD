---
title: "RML_project_US homocide"
author: "Krzysztof Osesik"
date: "15 06 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
Sys.setenv(LANGUAGE='en')
set.seed(123)
```

##

```{r, echo=FALSE}

# Setting up working directory
path_work<-"Z:/moje/moje/studia QPE/przedmioty/II semestr/Responsible ML/projekt/US homocide"
path_home<-"C:/Users/t420/Desktop/moje/studia QPE UW/przedmioty/II semestr/Responsible ML/projekt/US homocide"
path_home_2<-"C:/Users/Krzysztof_ASUS/Desktop/moje/studia QPE/przedmioty/II semestr/Responsible Machine Learning/project/US homocide"

location<-1

setwd(switch(location,path_work,path_home,path_home_2))

rm(list=ls())
```

# **Introduction**

## Problem Context

The Murder Accountability Project is the most complete database of homicides in the United States currently available. This dataset includes murders from the FBI's Supplementary Homicide Report from 1976 to the present. 

Dataset comes from Kaggle (https://www.kaggle.com/murderaccountability/homicide-reports).

The dataset consists of nearly 640,000 crime cases. They are described by 24 variables, for example City, State, Year, Crime Type, Victim's Age, Perpetrator's Age and Weapon Used. 


## Stakeholder

A stakeholder could be associated with a public authority aiming at ensuring that – in a case of a murder – identical effort is put into investigation with no regard for the victim’s race, sex or age. As a result similar crimes should be solved (alternatively not solved) independent of the victim’s race, sex  and age. 

The stakeholder is thus interested in evaluating the model’s general performance.  Their goal is to analyze whether there is some bias in police investigations towards certain social groups, which effectively results in a lower rate of solved crimes for those groups. 


## Objectives

The goal of the analysis is to determine whether fairness of the model is maintained. To that end, I analyze whether identified protected variables affect the outcome of the crime investigation. In the dataset victim's age, race and sex were identified as protected variables and whether a crime was solved or not was identified as target variable. In addition, explainability analysis was also conducted.

To sum up, the following are the objectives of the project:

1) Exploratory Data Analysis
2) Construction of predictive model
3) Explainability analysis
4) Assessment of model's fairness


## Data

The dataset consists of nearly 640,000 crime cases. They are described by 24 variables, for example City, State, Year, Crime Type, Victim's Age, Perpetrator's Age and Weapon Used. 

In addition, in order to increase computational efficiency, the dataset was reduced to look only at crimes in five U.S. States, i.e. Louisiana, Alabama, Mississippi, Georgia and South Carolina, which are known to be less friendly towards ethnic minorities (especially black). The timeframe of the analysis is 1980s (1980-1989).

Crime Solved was chosen as target variable. This variable defines whether a crime was solved or not. The remaining of 23 variables was chosen to be independent variables ( not all of which are relevant).

In the final model, the following variables were used:

*Target variable*

* Crime Solved 

The data is however imbalanced, as there is less than 30% of cases where crime remained unsolved. This will need to be dealt with in the process of the analysis.


*Explanatory variables*

1.	Agency Type (e.g. County Police, State Police, etc.)
2.	Victim’s Sex (Female, Male)
3.	Victim’s Race (e.g. Black, White, Native, etc.)
4.	Victim’s Age ( continuous 18-100 years old)
5.	Weapon (e.g. Knife, Gun, Poison, etc.)
6.	Victim’s Count ( how many additional victims there were – integral 0 – 10 people)

*Protected variables*

1.	Victim’s Sex
2.	Victim’s Race
3.	Victim’s Age 




<!-- Loading required libraries. -->

```{r, echo=FALSE,results="hide",, message=FALSE, warning=FALSE}
library(MASS)
library(tidyverse)
library(corrplot)
library(tidyselect)
library(scales)
library(dgof)
library(caTools)
library(pROC)
library(dummy)
library(smotefamily)
library(officer)
library(ROSE)
library(pscl)
library(caret)
library(OptimalCutpoints)
library(randomForest)
library(arm)
library(e1071)
library(DescTools)
library(reshape2)
library(lime)
library(DALEX)
library(vip)
library(pdp)
library(fairness)
library(DALEXtra)
library(fastshap)
```

<!-- Loading the data. -->

```{r, echo=FALSE,results="hide", message=FALSE, warning=FALSE}
# data<-read_csv(file = "database.csv")

# save(data,file="data.R")
load("data.R")
data_org<-data

```

The structure of the data is as follows. 

```{r,echo=FALSE,results="hide", message=FALSE, warning=FALSE}
dim(data)
# View(data)
summary(data)
```
```{r,echo=FALSE}
str(data)
```

<!-- Column names have spaces. Let's replace them with "_". -->


```{r, echo=FALSE, results="hide"}
temp<-colnames(data)

temp<-gsub(" ","_",temp)

colnames(data)<-temp


```

The dataset is for all U.S. states for years 1980-2014. However, we are only interested in a subset of that, namely in results for five states of Louisina,Alabama, Mississipi, Georgia and South Carolina (so-called US Deep South States) in the 1980s decade (1980-1989). These five states were known to be have been rather unfriendly to minorities, especially black minorities in those and previous years. 

```{r,echo=FALSE,results="hide", message=FALSE, warning=FALSE}
data<-subset(data, data$State %in% c("Louisiana","Alabama","Mississipi", "Georgia","South Carolina") & between(data$Year,1980, 1989))


```


<!-- Let's check if there are any empty values. -->


```{r,echo=FALSE,results="hide", message=FALSE, warning=FALSE}

temp<-sum(sapply(data,function(x) (length(x)==length(data$'Record_ID'))))-ncol(data)

if( temp==0){
  
  cat("There are no empty cells in the dataset and every column is equal in length.")
  
} else{
  
  cat("There are",temp,"column(s) in the dataset with empty cells.")
}
```


<!-- Now, let's check if there are any missing values. -->


```{r,echo=FALSE,results="hide", message=FALSE, warning=FALSE}

temp<-sum(sapply(data,function(x) (is.na(x))))

if( temp==0){
  
  cat("There are no missing values in the dataset")
  
} else{
  
  cat("There are",temp,"missing value(s) in the dataset.")
}
```
<!-- Since there is only 1 missing values in the dataset we can remove it from the data. -->

```{r,echo=FALSE,results="hide", message=FALSE, warning=FALSE}

data<-data[complete.cases(data),]

```

<!-- Let's remove variables which will not be used in the analysis. -->

```{r,echo=FALSE,results="hide", message=FALSE, warning=FALSE}
temp<-c("Record_ID" ,"Agency_Code","Agency_Name", "City", "State", "Year","Month","Incident","Record_Source", "Victim_Ethnicity", "Perpetrator_Ethnicity",
     "Crime_Type","Agency_Name","Perpetrator_Count","Perpetrator_Race","Perpetrator_Age","Perpetrator_Sex", "Relationship" )

data<-data[,-(which(colnames(data) %in% temp))]


```

In my analysis, I will only look at the cases with perpetrators over 18 years old and remove cases with Victim_age mistakenly assigned to 998.

```{r,echo=FALSE,results="hide", message=FALSE, warning=FALSE}

data<-subset(data,Victim_Age>=18 & Victim_Age!=998)

```



<!-- Let's turn character variables into factor. -->


```{r,echo=FALSE,results="hide", message=FALSE, warning=FALSE}

data<-data %>% 
 mutate_if(is.character,as.factor) 

```

<!-- Let's attach the data. -->

```{r,echo=FALSE,results="hide", message=FALSE, warning=FALSE}
attach(data)
```


# **Exploratory Data Analysis**

Let's look at the histogram of only one continuous variable in the dataset (Victim's Age). However, later on for the purpose of ease of analysis, the single continuous variable was turned into categorical one.


```{r,echo=FALSE,results="markup", message=FALSE, warning=FALSE}

data %>% 
  select(Victim_Age, Crime_Solved) %>% 
  ggplot(aes(x=Victim_Age,fill=Crime_Solved))+geom_density(alpha=0.4)+theme_bw()


```


<!-- Let's group categorical variables into fewer levels. -->

<!-- # FEATURE ENGINEERING -->

```{r,echo=FALSE,results="hide", message=FALSE, warning=FALSE}


data<-subset(data,subset=Victim_Sex!="Unknown" & Victim_Race!="Unknown")


data$Victim_Sex<-droplevels(data$Victim_Sex,exclude = anyNA(levels(data$Victim_Sex)))
data$Victim_Race<-droplevels(data$Victim_Race,exclude = anyNA(levels(data$Victim_Race)))


detach(data)

data$Weapon<-as.character(data$Weapon)

temp<-c("Firearm","Gun","Handgun","Rifle","Shotgun")

data$Weapon[which(data$Weapon %in% temp)]<-"Gun"

temp<-c("Strangulation","Suffocation")

data$Weapon[which(data$Weapon %in% temp)]<-"Suffocation"

data$Weapon<-as.factor(data$Weapon)


attach(data)

data$Victim_Age<-cut(data$Victim_Age,breaks=c(18,30,45,60,75,100), labels = c("18-30","30-45","45-60","60-75","75+"),right = FALSE)


```


Let's look at some distributions of categorical variables.


```{r,echo=FALSE,results="markup", message=FALSE, warning=FALSE}

temp<-colnames(data)

for (i in (temp)){
  
p<-data %>% 
  select(as.name(i)) %>% 
  ggplot(aes(x=eval(parse(text=i)),y=..count../sum(..count..)))+geom_bar(fill="sky blue",position = "dodge")+
  labs(y="Frequency", x=i)+
  theme_bw()+
  geom_text(aes(label=round(..count../sum(..count..),3)*100,y=(..count../sum(..count..))),stat="count",vjust=-.1)+
    theme(axis.text.x = element_text(angle=90))

print(p)


}



```

In our reduced dataset around 80% of crimes were solved. Most victims were male (ca. 75%), black (ca. 65%) and below 45 years of age (ca. 75%). gun was the most common weapon used to commit a crime.



Now, let's take a look at conditional distributions for protected categorical variables, i.e. Victim_Sex,  Victim_Race and Victim_Age conditional on whether the crime was solved or not.

```{r,echo=FALSE,results="markup", message=FALSE, warning=FALSE}


  p<-data %>% 
  select(Crime_Solved,Victim_Sex) %>% 
  ggplot(aes(x=Victim_Sex, group=Crime_Solved, y=(..prop..), fill=factor(..x..)))+geom_bar(position ="dodge")+
    facet_grid(~Crime_Solved)+
    geom_text(aes(y=(..prop..),label=scales::percent(round(..prop..,3))),stat="count", vjust=-.5)+
    scale_y_continuous(labels=scales::percent, limits=c(0,0.9))+
    labs(y="Percent", fill=Victim_Sex)+
    scale_fill_discrete(labels = levels(Victim_Sex))+
    theme_bw()+
    theme(axis.text.x = element_text(angle = 90))


print(p)


  p<-data %>%
  select(Crime_Solved,Victim_Age) %>%
  ggplot(aes(x=Victim_Age, group=Crime_Solved, y=(..prop..), fill=factor(..x..)))+geom_bar(position ="dodge")+
    facet_grid(~Crime_Solved)+
    geom_text(aes(y=(..prop..),label=scales::percent(round(..prop..,3))),stat="count", vjust=-.5)+
    scale_y_continuous(labels=scales::percent, limits=c(0,0.5))+
    labs(y="Percent", fill=Victim_Age)+
    scale_fill_discrete(labels = levels(Victim_Age))+
    theme_bw()+
    theme(axis.text.x = element_text(angle = 90))


print(p)

  p<-data %>% 
  select(Crime_Solved,Victim_Race) %>% 
  ggplot(aes(x=Victim_Race, group=Crime_Solved, y=(..prop..), fill=factor(..x..)))+geom_bar(position ="dodge")+
    facet_grid(~Crime_Solved)+
    geom_text(aes(y=(..prop..),label=scales::percent(round(..prop..,3))),stat="count", vjust=-.5)+
    scale_y_continuous(labels=scales::percent, limits=c(0,0.9))+
    labs(y="Percent", fill=Victim_Race)+
    scale_fill_discrete(labels = levels(Victim_Race))+
    theme_bw()+
    theme(axis.text.x = element_text(angle = 90))
   
   print(p)

```

From the first look at conditional distributions of protected variables there is no clear pattern of biases visible for victim's sex and victim's race. The exception is the victim's age variable. It seems like the younger the victim was, the higher was a probability that the crime would be solved. Older victims , i.e. people over 75 years of age constituted nearly 8% of unsolved cases, but only above 3% of solved cases.


Let's take a look at correlation (association) between categorical variables in the dataset. I will use Thiel's uncertainty coefficient to that.

```{r,echo=FALSE,results="markup", message=FALSE, warning=FALSE}

cor_df<-matrix(0,nrow=ncol(data), ncol=ncol(data), dimnames=list(colnames(data),colnames(data)))

for (i in 1:ncol(data)){
  
  for (j in 1:ncol(data)){
    
    temp<-UncertCoef(table(data[[i]],data[[j]]), direction = "column")
    
    cor_df[i,j]<-temp
    
  }
  
}

cor_df<-round(cor_df, 2)
cor_df<-melt(cor_df)

ggplot(cor_df,aes(x=Var1,y=Var2,fill=value))+geom_tile()+labs(title = "Uncertainity Coefficient for categorical variables")+geom_text(aes(Var1, Var2, label = value), color = "black", size = 4)+scale_fill_gradient(low="white", high="blue") 


```

The variables do not seem to be correlated.



# **MODELLING**


In the modelling part of the analysis I will use three algorithms: 

1. logistic regression
2. random forest 
3. support vector mechanism 


The algorithm that offers the best results will be the basis of further analysis in terms of explainability and fairness. 

Let's first divide the dataset into training and test sets.

```{r,echo=FALSE,results="hide", message=FALSE, warning=FALSE}
temp<-sample.split(data$Crime_Solved,SplitRatio = 0.7)

train_set<-subset(data, temp==TRUE)
test_set<-subset(data, temp==FALSE)

```

Let's see if proportions of Yes/No in target variable are maintained.

```{r,echo=FALSE,results="markup", message=FALSE, warning=FALSE}

cat("The proportion of cases in the original dataset:")
round(prop.table(table(data$Crime_Solved)),4)*100
cat("\n ")
cat("The proportion of cases in the train set dataset:")
round(prop.table(table(train_set$Crime_Solved)),4)*100
cat("\n ")
cat("The proportion of cases in the test set dataset:")
round(prop.table(table(test_set$Crime_Solved)),4)*100

```

Proportions of binary responses of target variable have been maintained in the training and testing sets. Now, I need to deal with high imbalance of the training dataset. To that end, I will apply both oversampling and undersampling methods. This method was found to provide better results than oversampling and/or undersampling on a stand-alone basis.


```{r,echo=FALSE,results="markup", message=FALSE, warning=FALSE}

train_set_balanced<-ovun.sample(Crime_Solved~., data=train_set,method="both",p=0.5)

train_set_balanced<-train_set_balanced$data

table(train_set_balanced$Crime_Solved)


```


## LOGISTIC REGRESSION

Let's start predictive modelling. First, logistic regression model will be applied. Let's look at its summary.

```{r,echo=FALSE,results="markup", message=FALSE, warning=FALSE}
train_set_balanced$Crime_Solved<-ifelse(train_set_balanced$Crime_Solved=="Yes",1,0)

train_set_balanced$Crime_Solved<-factor(train_set_balanced$Crime_Solved, levels=c(0,1))

model_log<-glm(Crime_Solved~.,data=train_set_balanced, family=binomial (link="logit"))

summary(model_log)

```

Some dummy variables are indicated as significant. Now, let's look at some other diagnostics.


```{r,echo=FALSE,results="markup", message=FALSE, warning=FALSE}


cat("McFadden R-squared for logistic regression is equal to:")
pR2(model_log)["McFadden"]

cat("\n")
anova(model_log, test="Chisq")

vars_imp<-varImp(model_log)

vars_type<-rownames(vars_imp)

vars_imp<-cbind(vars_type,vars_imp)

rownames(vars_imp)<-NULL

cat("\n")
head(vars_imp[order(vars_imp$Overall,decreasing = TRUE),],10)



```


From the anova analysis, it looks like for the logistic regression model - Weapon, Agency Type and Victim's Age are the most important explanatory variables. 

Now, let's try predict values based on a test set data and evaluate confusion matrix and ROC curve.

```{r,echo=FALSE,results="markup", message=FALSE, warning=FALSE}

test_set$Crime_Solved<-ifelse(test_set$Crime_Solved=="Yes",1,0)

pred_log<-predict(model_log, test_set[-2],type="response")
pred_log_bin<-ifelse(pred_log>=0.5,1,0)

confusionMatrix(as.factor(pred_log_bin),as.factor(test_set$Crime_Solved), positive = "0")


roc<-roc(test_set$Crime_Solved~pred_log,plot=TRUE,print.auc=TRUE,col="green",lwd =4,legacy.axes=TRUE,main="ROC Curve - Logistic Regression")


```

Let's look at the results of logistic regression modeling with a use of cross-validiation.

```{r,echo=FALSE,results="markup", message=FALSE, warning=FALSE}

ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
mod_log_cv <- train(Crime_Solved~.,  data=train_set_balanced, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5)

pred_log_cv <- predict(mod_log_cv, newdata=test_set[-2], type="prob")

pred_log_cv_bin<-ifelse(pred_log>=0.5,1,0)

confusionMatrix(as.factor(pred_log_cv_bin),as.factor(test_set$Crime_Solved))


roc<-roc(test_set$Crime_Solved~pred_log_cv[,2],plot=TRUE,print.auc=TRUE,col="green",lwd =4,legacy.axes=TRUE,main="ROC Curve - Logistic Regression Cross Validation")

```

The results with or without the use of cross-validation are identical. 


Now, let's apply random forest algorithm using randomForest package. LEt's investigate confusion matrix and ROC curve.


##Random Forest

```{r,echo=FALSE,results="markup", message=FALSE, warning=FALSE}

model_rf<-randomForest(Crime_Solved~.,data=train_set_balanced, ntree=30 )

pred_rf<-predict(model_rf,newdata=test_set[-2],type="prob")

pred_rf_bin<-ifelse(pred_rf[,2]>0.5,1,0)

confusionMatrix(as.factor(pred_rf_bin),as.factor(test_set$Crime_Solved))

roc<-roc(test_set$Crime_Solved~pred_rf[,2],plot=TRUE,print.auc=TRUE,col="green",lwd =4,legacy.axes=TRUE,main="ROC Curve - Random Forest")


model_rf

```

Let's look at some additional diagnostics for the random forest model.


```{r,echo=FALSE,results="markup", message=FALSE, warning=FALSE}

obb_error_df<-data.frame(
  Trees=rep(1:nrow(model_rf$err.rate), times=3),
  Type=rep(c("OOB","0","1"), each=nrow(model_rf$err.rate)),
  Error=c(model_rf$err.rate[,"OOB"],
          model_rf$err.rate[,"0"],
          model_rf$err.rate[,"1"]))


ggplot(data=obb_error_df, aes(x=Trees, y=Error))+geom_line(aes(color=Type))+theme_bw()+labs(main="Random forest out-of-bag error & number of trees")

oob_values<-vector(length=10)

for (i in 1:(ncol(data)-1)){
  
  temp_model_rf<-randomForest(Crime_Solved~.,data=train_set_balanced, ntree=30,mtry=i)
  
  oob_values[i]<-temp_model_rf$err.rate[nrow(temp_model_rf$err.rate),1]
  
```

It looks like out-of-bag error rate stabilizes at around 30 trees.


```{r,echo=FALSE,results="markup", message=FALSE, warning=FALSE}

varImp<-importance(model_rf)

varImpPlot(model_rf)


}

```

It looks like the most important variable for the random forest algorithm was Weapon and then Agency_Type and Victim_Age.




## SVM

Now, let us apply support vector mechanism (SVM) algorithm.

```{r}

set.seed(123)



model_svm_tuned<-tune(svm,Crime_Solved~.,data=train_set_balanced,
                      kernel="radial",
                      ranges=list(gamma=2^(0),cost=10^(0)))

model_svm_tuned$best.parameters

```

Let's use the best parameters found by tuning the svm model.



```{r}


model_svm<-svm(Crime_Solved~.,data=train_set_balanced, kernel="radial",
               gamma=model_svm_tuned$best.parameters$gamma,
               cost=model_svm_tuned$best.parameters$cost,
               type="C-classification",
               scale=TRUE)


summary(model_svm)

```

Let's predict repsonses based on test set and evaluate confusion matrix.

```{r}

pred_svm<-predict(model_svm,newdata=test_set[-2])


confusionMatrix(as.factor(pred_svm),as.factor(test_set$Crime_Solved))


roc<-roc(test_set$Crime_Solved~as.numeric(as.character(pred_svm)),plot=TRUE,print.auc=TRUE,col="green",lwd =4,legacy.axes=TRUE,main="ROC Curve - SVM")

```

SVM performs very similarly to Random forest model. However, Random forest model, at the cost of slightly worse model accuracy (positive prediction value is the same) fares better in terms of sensitivity metrics, i.e. in identifying positive cases ( for the purpose of our analysis "positive case" is associated with crime not-solved - factor level "0"). Therefore, in the subsequent parts, i.e. explainability analysis and fairness analysis Random forest will be used.



# EXPLAINABILITY  ANALYSIS

In the explainability part I will focus on:

1.two global metrics:

  +     variable importance plots
  +     partial dependence plots
  
2. two local metrics:

  +     LIME
  +     Shapley Values



## VARIABLE IMPORTANCE PLOTS

```{r}

explain_rf <- DALEX::explain(model = model_rf,  
                        data = test_set[,-2],
                           y = test_set$Crime_Solved,
                        label="Random Forest")


# loss_root_mean_square(observed = test_set$Crime_Solved, 
#                    predicted = predict(model_rf, test_set))
                   

set.seed(123)
vip_50<-model_parts(explainer = explain_rf, 
        loss_function = loss_root_mean_square,
                    B = 30,
        type="raw")


plot(vip_50)


```



## PARTIAL DEPENDENCE PLOTS


```{r}

explain_rf <- DALEX::explain(model = model_rf,  
                        data = test_set[,-2],
                           y = test_set$Crime_Solved,
                        label="Random Forest")


pdp_fun<-function(x){
  
  
  
  pdp_rf<-model_profile(explainer=explain_rf, variables=x,
                        # groups=,
                        )
  

}

col_n<-colnames(test_set)[-2]


for (i in seq_along(col_n)){
  
print(plot(pdp_fun(col_n[i])))
  
}



```



##LIME

```{r}

model_rf<-as_classifier(model_rf, labels = NULL)

test_set$Crime_Solved<-as.factor(test_set$Crime_Solved)
test_set$Victim_Count<-as.numeric(test_set$Victim_Count)


explainer <- lime(train_set_balanced[,-2], model_rf, quantile_bins = FALSE)

set.seed(123)

d_test<-subset(test_set,test_set$Victim_Race=="Black"& test_set$Victim_Age=="75+"&test_set$Weapon=="Gun"& test_set$Agency_Type=="Sheriff"&test_set$Victim_Sex=="Male")

explanation <- lime::explain(d_test[c(3:4,(nrow(d_test)-1):nrow(d_test)),-2], explainer,n_labels=1, n_features = 6, n_permutations=100)


explanation


plot_features(explanation)


```

## SHAPLEY VALUES

Now, let's look at an alternative approach, i.e. so-called Shapley values.

```{r}

explain_rf <- DALEX::explain(model = model_rf,  
                        data = test_set[,-2],
                           y = test_set$Crime_Solved,
                        label="Random Forest")
predict(explain_rf, test_set[3:5,])



shap <- predict_parts(explainer = explain_rf, 
                      new_observation = d_test[3,], 
                                 type = "shap",
                                    B = 25)

shap

plot(shap)

```


Now, let's turn to fairness analysis. Here I will use four metrics:

1. Predictive rate parity
2. Demographic parity
3. Proportional parity
4. Equalized odds

At the stage of explanatory model analysis, I identyfied three potential protected variables, i.e.:

1.	Victim’s Sex
2.	Victim’s Race
3.	Victim’s Age

However, in all models applied, and in the Random Forest in particular Victim's Race does not seem to be a significant variable, which indicates that racial profiling did not have much weight on crime investigations. In turn, out of the three protected variables, Victim's Age seems most significant, followed by Victim's Sex. Thus, in the subsequent fairness analysis I will only focus on these two protected variables.

# FAIRNESS ANALYSIS

## PREDICTIVE RATE PARITY

Before looking at predictive rate parity, let's first look at the densities of predicted probabilites for different subgroups of Victim's Age and Victim's Sex in the dataset.

```{r}

test_set_fair<-cbind(test_set,pred_rf)

colnames(test_set_fair)[(ncol(test_set_fair)-1):ncol(test_set_fair)]<-c("probs_0","probs_1")

prp_sex <- pred_rate_parity(data         = test_set_fair, 
                         outcome      = "Crime_Solved", 
                         outcome_base = '0', 
                         group        = 'Victim_Sex',
                         probs        = 'probs_1', 
                         cutoff       = 0.5, 
                         base         = 'Female')




prp_age <- pred_rate_parity(data         = test_set_fair, 
                         outcome      = "Crime_Solved", 
                         outcome_base = '0', 
                         group        = 'Victim_Age',
                         probs        = 'probs_1', 
                         cutoff       = 0.5, 
                         base         = '30-45')


prp_sex[3]
prp_age[3]

"Formula: TP / (TP + FP) - precision"

```

Now, let's see predictive rate parity results.


```{r}
prp_sex[1:2]
prp_age[1:2]


```

## DEMOGRAPHIC PARITY


```{r}


dem_par_sex <- dem_parity(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '0', 
                      group        = 'Victim_Sex',
                      probs        = 'probs_1',
                      base         = "Female")
dem_par_sex[1:2]



dem_par_age <- dem_parity(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '0', 
                      group        = 'Victim_Age',
                      probs        = 'probs_1',
                      base         = "30-45")
dem_par_age[1:2]


"Formula: (TP + FP) - absolute number of all positively classified individuals in all subgroups"

```


## PROPORTIONAL PARITY

```{r}

prop_par_sex <- prop_parity(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '0', 
                      group        = 'Victim_Sex',
                      probs        = 'probs_1',
                      base         = "Female")
prop_par_sex[1:2]


prop_par_age <- prop_parity(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '0', 
                      group        = 'Victim_Age',
                      probs        = 'probs_1',
                      base         = "30-45")
prop_par_age[1:2]

"Formula: (TP + FP) / (TP + FP + TN + FN) - proportion of all positively classified individuals in all subgroups"

```



## EQUALIZED ODDS

```{r}

eq_odds_sex <- equal_odds(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '0', 
                      group        = 'Victim_Sex',
                      probs        = 'probs_1',
                      base         = "Female")
eq_odds_sex[1:2]



eq_odds_age <- equal_odds(data     = test_set_fair, 
                      outcome      = 'Crime_Solved',
                      outcome_base = '0', 
                      group        = 'Victim_Age',
                      probs        = 'probs_1',
                      base         = "30-45")

eq_odds_age[1:2]

"Formula: TP / (TP + FN) - sensitivity"

```


# SUMMARY
